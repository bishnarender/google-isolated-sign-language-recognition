{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:50:58.934808Z",
     "iopub.status.busy": "2023-05-23T01:50:58.933940Z",
     "iopub.status.idle": "2023-05-23T01:50:58.944920Z",
     "shell.execute_reply": "2023-05-23T01:50:58.944052Z",
     "shell.execute_reply.started": "2023-05-23T01:50:58.934770Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:50:58.946804Z",
     "iopub.status.busy": "2023-05-23T01:50:58.946413Z",
     "iopub.status.idle": "2023-05-23T01:51:17.921208Z",
     "shell.execute_reply": "2023-05-23T01:51:17.919963Z",
     "shell.execute_reply.started": "2023-05-23T01:50:58.946770Z"
    },
    "id": "IpEQKDrDqAFP",
    "outputId": "2affcd98-7204-4d46-c030-ce8daefe9ad4"
   },
   "outputs": [],
   "source": [
    "# ## !pip3 install -q /kaggle/input/islr-utils/tensorflow-2.12.0-cp38-cp38-linux_2_17_x86_64.whl\n",
    "# !pip3 install -q /kaggle/input/islr-utils/tensorflow-2.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "    \n",
    "# !pip3 install -q tensorflow-addons==0.20.0\n",
    "# !pip3 install -q tensorflow-probability==0.19.0\n",
    "# !pip3 install -q opencv-python-headless==4.7.0.72\n",
    "# !pip3 install -q seaborn==0.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:51:17.922978Z",
     "iopub.status.busy": "2023-05-23T01:51:17.922638Z",
     "iopub.status.idle": "2023-05-23T01:51:48.403746Z",
     "shell.execute_reply": "2023-05-23T01:51:48.402691Z",
     "shell.execute_reply.started": "2023-05-23T01:51:17.922944Z"
    },
    "id": "wD7tqFC_qAFQ",
    "outputId": "426ff58f-01d7-451e-ea99-7b00405d8781"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 07:09:44.174335: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 07:09:44.955190: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/na/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_4361/1306860445.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'schedules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# classes from utils folder\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mschedules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneCycleLR, ListedLR\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Snapshot, SWA\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlearners\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FGM, AWP\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'schedules'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow.keras.mixed_precision as mixed_precision\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "import sklearn\n",
    "\n",
    "# classes from utils folder\n",
    "from schedules import OneCycleLR, ListedLR\n",
    "from callbacks import Snapshot, SWA\n",
    "from learners import FGM, AWP\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import gc\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "print(f'Tensorflow Version: {tf.__version__}')\n",
    "print(f'Python Version: {sys.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### tf.Tensor vs Tensor\n",
    "# ### tf.Tensor([1. 3.], shape=(2,), dtype=float32) vs Tensor(\"args_0:0\", shape=(None, 543, 3), dtype=float32)\n",
    "# ### Tensor: symbolic tensors which represent nodes in an execution graph.\n",
    "# ### symbolic tensor differs from other tensors in that they do not specifically hold values.\n",
    "# ### it is not meaningful to call .numpy() on a symbolic tensor as the graph executor does not have access to a python runtime.\n",
    "\n",
    "\n",
    "# ### for displaying tensor values - run in eager execution mode - mainly for debugging purposes.\n",
    "# ### Eager execution is a powerful execution environment that evaluates operations immediately. It does not build graphs, and the operations return actual values instead of computational graphs to run later.\n",
    "# tf.compat.v1.enable_eager_execution() # OR tf.config.run_functions_eagerly(True)\n",
    "# tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:51:48.406510Z",
     "iopub.status.busy": "2023-05-23T01:51:48.405998Z",
     "iopub.status.idle": "2023-05-23T01:51:48.410686Z",
     "shell.execute_reply": "2023-05-23T01:51:48.409862Z",
     "shell.execute_reply.started": "2023-05-23T01:51:48.406481Z"
    }
   },
   "outputs": [],
   "source": [
    "## TPU: check the list of /dev/accel3 \n",
    "# !ls -ltrh /dev/accel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    n_splits = 5\n",
    "    save_output = True\n",
    "    output_dir = '/kaggle/working'\n",
    "    loc = '/kaggle/working'\n",
    "    \n",
    "    seed = 42\n",
    "    verbose = 2 #0) silent 1) progress bar 2) one line per epoch    \n",
    "    max_len = 384\n",
    "    \n",
    "    \n",
    "    replicas = 8\n",
    "    lr = 5e-4# 5e-4 * replicas\n",
    "    weight_decay = 0.1\n",
    "    lr_min = 1e-6\n",
    "    epoch = 350 #300 #400\n",
    "    warmup = 0\n",
    "    batch_size = 64#64 * replicas #16 * replicas\n",
    "    snapshot_epochs = []\n",
    "    swa_epochs = [] #list(range(epoch//2,epoch+1))\n",
    "    \n",
    "    fp16 = True\n",
    "    fgm = False\n",
    "    awp = True\n",
    "    awp_lambda = 0.2\n",
    "    awp_start_epoch = 15\n",
    "    dropout_start_epoch = 15\n",
    "    resume = 0\n",
    "    decay_type = 'cosine'\n",
    "    dim = 192\n",
    "    comment = f'islr-fp16-192-8-seed{seed}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:51:48.412003Z",
     "iopub.status.busy": "2023-05-23T01:51:48.411700Z",
     "iopub.status.idle": "2023-05-23T01:51:59.154796Z",
     "shell.execute_reply": "2023-05-23T01:51:59.153838Z",
     "shell.execute_reply.started": "2023-05-23T01:51:48.411979Z"
    },
    "id": "u74o98JxqAFQ",
    "outputId": "af042ef9-76e7-40a2-9938-e5fd4bb6f495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using single GPU\n",
      "Num GPUs Available:  1\n",
      "REPLICAS: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 20:09:35.807975: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-29 20:09:35.828792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-29 20:09:35.828976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Seed all random number generators\n",
    "def seed_everything(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "def get_strategy(device='TPU-VM'):    \n",
    "    if \"TPU\" in device:\n",
    "        tpu = 'local' if device=='TPU-VM' else None\n",
    "        print(\"connecting to TPU...\")\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu='local')\n",
    "        strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        IS_TPU = True\n",
    "\n",
    "    if device == \"GPU\"  or device==\"CPU\":\n",
    "        ngpu = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "        if ngpu>1:\n",
    "            print(\"Using multi GPU\")\n",
    "            strategy = tf.distribute.MirroredStrategy()\n",
    "        elif ngpu==1:\n",
    "            print(\"Using single GPU\")\n",
    "            strategy = tf.distribute.get_strategy()\n",
    "        else:\n",
    "            print(\"Using CPU\")\n",
    "            strategy = tf.distribute.get_strategy()\n",
    "            CFG.device = \"CPU\"\n",
    "        IS_TPU = False\n",
    "\n",
    "    if device == \"GPU\":\n",
    "        print(\"Num GPUs Available: \", ngpu)\n",
    "        \n",
    "    # tf.data tracks the time spent in each operation of the input pipeline to find a good allocation of its CPU budget.\n",
    "    # tf.data runs an optimization algorithm to find a good allocation of its CPU budget across all parameters specified as \"AUTOTUNE\".    \n",
    "    AUTO     = tf.data.experimental.AUTOTUNE\n",
    "    REPLICAS = strategy.num_replicas_in_sync\n",
    "    print(f'REPLICAS: {REPLICAS}')\n",
    "    \n",
    "    return strategy, REPLICAS, IS_TPU\n",
    "\n",
    "STRATEGY, N_REPLICAS, IS_TPU = get_strategy(\"GPU\")#\"TPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:51:59.156254Z",
     "iopub.status.busy": "2023-05-23T01:51:59.155966Z",
     "iopub.status.idle": "2023-05-23T01:51:59.163783Z",
     "shell.execute_reply": "2023-05-23T01:51:59.162991Z",
     "shell.execute_reply.started": "2023-05-23T01:51:59.156228Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:51:59.165015Z",
     "iopub.status.busy": "2023-05-23T01:51:59.164754Z",
     "iopub.status.idle": "2023-05-23T01:51:59.184611Z",
     "shell.execute_reply": "2023-05-23T01:51:59.183743Z",
     "shell.execute_reply.started": "2023-05-23T01:51:59.164993Z"
    },
    "id": "QVDc3vkwqAFQ",
    "outputId": "b84108e5-9e50-4a46-eca8-6a60ecdde99c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILENAMES = glob.glob('islr_records/*.tfrecords')\n",
    "print(len(TRAIN_FILENAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:51:59.185941Z",
     "iopub.status.busy": "2023-05-23T01:51:59.185650Z",
     "iopub.status.idle": "2023-05-23T01:51:59.364765Z",
     "shell.execute_reply": "2023-05-23T01:51:59.363829Z",
     "shell.execute_reply.started": "2023-05-23T01:51:59.185917Z"
    },
    "id": "DtrBI-jwqAFQ",
    "outputId": "3ebb3c2b-8fbe-4552-8a16-d50484823b57"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  participant_id  sequence_id  \\\n",
       "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
       "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
       "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
       "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
       "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
       "\n",
       "    sign  \n",
       "0   blow  \n",
       "1   wait  \n",
       "2  cloud  \n",
       "3   bird  \n",
       "4   owie  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94477 entries, 0 to 94476\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   path            94477 non-null  object\n",
      " 1   participant_id  94477 non-null  int64 \n",
      " 2   sequence_id     94477 non-null  int64 \n",
      " 3   sign            94477 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train DataFrame\n",
    "train_df = pd.read_csv('train.csv')\n",
    "display(train_df.head())\n",
    "display(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "415\n",
      "299\n",
      "377.908\n"
     ]
    }
   ],
   "source": [
    "a = train_df.sign.value_counts()\n",
    "print(len(a))\n",
    "print(max(a))\n",
    "print(min(a))\n",
    "print(train_df.sign.value_counts().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:51:59.366182Z",
     "iopub.status.busy": "2023-05-23T01:51:59.365881Z",
     "iopub.status.idle": "2023-05-23T01:51:59.373243Z",
     "shell.execute_reply": "2023-05-23T01:51:59.372364Z",
     "shell.execute_reply.started": "2023-05-23T01:51:59.366156Z"
    },
    "id": "iAc9FKztqAFQ",
    "outputId": "ade0413c-5a17-4a4f-f5a6-b0048ab76ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93184 94477\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def count_data_items(filenames):\n",
    "    # filename => islr_records/fold3-5-512.tfrecords\n",
    "    # re.compile(r\"-([0-9]*)\\.\").search(filename.split('/')[-1]) => <re.Match object; span=(7, 12), match='-512.'>\n",
    "    # re.compile(r\"-([0-9]*)\\.\").search(filename.split('/')[-1]).group(1) => 512\n",
    "    \n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename.split('/')[-1]).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "print(count_data_items(TRAIN_FILENAMES), len(train_df))\n",
    "# assert count_data_items(TRAIN_FILENAMES) == len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:51:59.377290Z",
     "iopub.status.busy": "2023-05-23T01:51:59.376890Z",
     "iopub.status.idle": "2023-05-23T01:51:59.413531Z",
     "shell.execute_reply": "2023-05-23T01:51:59.412683Z",
     "shell.execute_reply.started": "2023-05-23T01:51:59.377253Z"
    },
    "id": "6xyloTyiqAFQ",
    "outputId": "dab46b40-8d61-4eb7-a7a5-4d5e10ab8538"
   },
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543\n",
    "MAX_LEN = 384\n",
    "CROP_LEN = MAX_LEN\n",
    "NUM_CLASSES  = 250\n",
    "PAD = -100.\n",
    "\n",
    "\n",
    "# keypoints/indices of landmarks can be found zooming the image \"images/indices_landmarks.png\".\n",
    "# OR--------------\n",
    "# https://github.com/tensorflow/tfjs-models/blob/838611c02f51159afdd77469ce67f0e26b7bbb23/face-landmarks-detection/src/mediapipe-facemesh/keypoints.ts\n",
    "NOSE=[1,2,98,327]\n",
    "LNOSE = [98]\n",
    "RNOSE = [327]\n",
    "LIP = [ 0, \n",
    "    61, 185, 40, 39, 37, 267, 269, 270, 409,\n",
    "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "]\n",
    "LLIP = [84,181,91,146,61,185,40,39,37,87,178,88,95,78,191,80,81,82]\n",
    "RLIP = [314,405,321,375,291,409,270,269,267,317,402,318,324,308,415,310,311,312]\n",
    "POSE = [500, 502, 504, 501, 503, 505, 512, 513]\n",
    "LPOSE = [513,505,503,501]\n",
    "RPOSE = [512,504,502,500]\n",
    "REYE = [\n",
    "    33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "    246, 161, 160, 159, 158, 157, 173,\n",
    "]\n",
    "LEYE = [\n",
    "    263, 249, 390, 373, 374, 380, 381, 382, 362,\n",
    "    466, 388, 387, 386, 385, 384, 398,\n",
    "]\n",
    "\n",
    "# np.arange(468, 489).tolist() => [468, 469, 470, 471, 472, ..., 487, 488]\n",
    "LHAND = np.arange(468, 489).tolist()\n",
    "RHAND = np.arange(522, 543).tolist()\n",
    "\n",
    "POINT_LANDMARKS = LIP + LHAND + RHAND + NOSE + REYE + LEYE #+POSE\n",
    "\n",
    "NUM_NODES = len(POINT_LANDMARKS)\n",
    "CHANNELS = 6*NUM_NODES\n",
    "\n",
    "# NUM_NODES => 118\n",
    "# CHANNELS => 708\n",
    "\n",
    "\n",
    "def tf_nan_mean(x, axis=0, keepdims=False):\n",
    "    # tf.math.reduce_sum(input_tensor, axis=None, keepdims=False) => computes the sum of elements across dimensions of a tensor.\n",
    "    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis, keepdims=keepdims) / tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis, keepdims=keepdims)\n",
    "\n",
    "def tf_nan_std(x, center=None, axis=0, keepdims=False):\n",
    "    if center is None:\n",
    "        center = tf_nan_mean(x, axis=axis,  keepdims=True)\n",
    "    d = x - center\n",
    "    # tf.math.sqrt(x,) => computes element-wise square root of the input tensor.\n",
    "    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis, keepdims=keepdims))\n",
    "\n",
    "class Preprocess(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len=MAX_LEN, point_landmarks=POINT_LANDMARKS, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.max_len = max_len\n",
    "        self.point_landmarks = point_landmarks\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if tf.rank(inputs) == 3:\n",
    "            # inputs.shape => (64, 543, 3) i.e., 1st example out of 512.\n",
    "            x = inputs[None,...]            \n",
    "            # x.shape => => (1, 64, 543, 3) i.e., 1st example out of 512.\n",
    "        else:\n",
    "            x = inputs\n",
    "        \n",
    "        # tf.gather(x, [17], axis=2).shape => (1, None, 1, 3) => (1, 64, 1, 3)\n",
    "        mean = tf_nan_mean(tf.gather(x, [17], axis=2), axis=[1,2], keepdims=True)\n",
    "        # mean => tf.Tensor([[[[ 0.42181498  0.6313379  -0.04615781]]]], shape=(1, 1, 1, 3), dtype=float32)\n",
    "        mean = tf.where(tf.math.is_nan(mean), tf.constant(0.5,x.dtype), mean)\n",
    "        \n",
    "        x = tf.gather(x, self.point_landmarks, axis=2) #N,T,P,C\n",
    "        # x => tf.Tensor(..., shape=(1, 64, 118, 3), dtype=float32)\n",
    "        \n",
    "        std = tf_nan_std(x, center=mean, axis=[1,2], keepdims=True)\n",
    "        # std => tf.Tensor([[[[0.15967554 0.06721658 0.04615425]]]], shape=(1, 1, 1, 3), dtype=float32)\n",
    "        \n",
    "        x = (x - mean)/std     \n",
    "        if self.max_len is not None:\n",
    "            x = x[:,:self.max_len]\n",
    "            # x.shape => (1, 64, 118, 3)\n",
    "            \n",
    "        length = tf.shape(x)[1]\n",
    "        x = x[...,:2]# take prior 2 values from last dimension.\n",
    "        # x.shape => (1, 64, 118, 2)\n",
    "        \n",
    "        # x[:,1:].shape, x[:,:-1].shape => (1, 63, 118, 2), (1, 63, 118, 2) \n",
    "        # (x[:,1:] - x[:,:-1]).shape => (1, 63, 118, 2)\n",
    "        \n",
    "        # tf.pad(tensor, paddings, mode='CONSTANT', constant_values=0,) => pads a tensor.\n",
    "        # tf.cond(pred, true_fn=None, false_fn=None,) => Return true_fn() if the \"pred\" is true else false_fn().\n",
    "        # [0, 0] => add 0 value before and 0 value after to the dimension 0 (axis=0).\n",
    "        # [0, 1] => add 0 value before and 1 value after to the dimension 1 (axis=1). \n",
    "        # [0, 0] => add 0 value before and 0 value after to the dimension 2 (axis=2).\n",
    "        # [0, 0] => add 0 value before and 1 value after to the dimension 3 (axis=3).         \n",
    "        dx = tf.cond(tf.shape(x)[1]>1,lambda:tf.pad(x[:,1:] - x[:,:-1], [[0,0],[0,1],[0,0],[0,0]], constant_values=1.),lambda:tf.ones_like(x))\n",
    "        #dx = tf.cond(tf.shape(x)[1]>1,lambda:tf.pad(x[:,1:] - x[:,:-1], [[0,0],[0,1],[0,0],[0,0]]),lambda:tf.zeros_like(x))\n",
    "        # dx.shape => (1, 64, 118, 2)\n",
    "\n",
    "        dx2 = tf.cond(tf.shape(x)[1]>2,lambda:tf.pad(x[:,2:] - x[:,:-2], [[0,0],[0,2],[0,0],[0,0]], constant_values=1.), lambda:tf.ones_like(x))\n",
    "        #dx2 = tf.cond(tf.shape(x)[1]>2,lambda:tf.pad(x[:,2:] - x[:,:-2], [[0,0],[0,2],[0,0],[0,0]]),lambda:tf.zeros_like(x))        \n",
    "        # dx2.shape => (1, 64, 118, 2)\n",
    "        \n",
    "        # tf.reshape(x, (-1,length,2*len(self.point_landmarks))).shape => (1, 64, 236)\n",
    "        x = tf.concat([\n",
    "            tf.reshape(x, (-1,length,2*len(self.point_landmarks))),\n",
    "            tf.reshape(dx, (-1,length,2*len(self.point_landmarks))),\n",
    "            tf.reshape(dx2, (-1,length,2*len(self.point_landmarks))),\n",
    "        ], axis = -1)\n",
    "        \n",
    "        # x.shape => (1, 64, 708)\n",
    "        x = tf.where(tf.math.is_nan(x),tf.constant(1.,x.dtype),x)#0.\n",
    " \n",
    "        return x\n",
    "    \n",
    "def interp1d_(x, target_len, method='random'):\n",
    "    # x.shape => (114, 543, 3)\n",
    "    \n",
    "    length = tf.shape(x)[1]\n",
    "    target_len = tf.maximum(1, target_len)\n",
    "    if method == 'random':\n",
    "        if tf.random.uniform(()) < 0.35:#0.33\n",
    "            x = tf.image.resize(x, (target_len, tf.shape(x)[1]),'bilinear')\n",
    "        else:\n",
    "            if tf.random.uniform(()) < 0.5:\n",
    "                x = tf.image.resize(x, (target_len, tf.shape(x)[1]),'bicubic')\n",
    "            else:\n",
    "                x = tf.image.resize(x, (target_len, tf.shape(x)[1]),'nearest')\n",
    "    else:\n",
    "        x = tf.image.resize(x, (target_len, tf.shape(x)[1]), method)\n",
    "        \n",
    "    # x.shape => (108, 543, 3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:51:59.414913Z",
     "iopub.status.busy": "2023-05-23T01:51:59.414622Z",
     "iopub.status.idle": "2023-05-23T01:52:04.003230Z",
     "shell.execute_reply": "2023-05-23T01:52:04.001989Z",
     "shell.execute_reply.started": "2023-05-23T01:51:59.414889Z"
    },
    "id": "r17ZnZaGqAFQ"
   },
   "outputs": [],
   "source": [
    "def decode_tfrec(record_bytes):\n",
    "    features = tf.io.parse_single_example(record_bytes, {\n",
    "        'coordinates': tf.io.FixedLenFeature([], tf.string),\n",
    "        'sign': tf.io.FixedLenFeature([], tf.int64),\n",
    "    })\n",
    "    \n",
    "    out = {}\n",
    "    out['coordinates']  = tf.reshape(tf.io.decode_raw(features['coordinates'], tf.float32), (-1,ROWS_PER_FRAME,3))\n",
    "    out['sign'] = features['sign']\n",
    "    # out => {'coordinates': <tf.Tensor 'Reshape:0' shape=(None, 543, 3) dtype=float32>, 'sign': <tf.Tensor 'ParseSingleExample/ParseExample/ParseExampleV2:1' shape=() dtype=int64>}\n",
    "    return out\n",
    "\n",
    "def filter_nans_tf(x, ref_point=POINT_LANDMARKS):\n",
    "    # x => Tensor(\"args_0:0\", shape=(None, 543, 3), dtype=float32)\n",
    "    # args_0:0 => is label of tensor\n",
    "    \n",
    "    # one of the result from print(x) =>\n",
    "    # tf.Tensor(\n",
    "    # [[[ 0.48363915  0.5613689  -0.04201406]\n",
    "    #   [ 0.42014915  0.5304688  -0.0615425 ]\n",
    "    #   [ 0.4342317   0.54189897 -0.03884678]\n",
    "    #   ...\n",
    "    #   [        nan         nan         nan]\n",
    "    #   [        nan         nan         nan]\n",
    "    #   [        nan         nan         nan]]\n",
    "    #  ...\n",
    "    #  [[ 0.4484162   0.56412005 -0.03462385]\n",
    "    #   [ 0.42517775  0.5413078  -0.05620537]\n",
    "    #   [ 0.43741626  0.55028653 -0.03224123]\n",
    "    #   ...\n",
    "    #   [ 0.48019624  0.60859764  0.00434037]\n",
    "    #   [ 0.49120402  0.6069662   0.01751086]\n",
    "    #   [ 0.48884943  0.610221    0.02671014]]], shape=(12, 543, 3), dtype=float32)    \n",
    "\n",
    "    # POINT_LANDMARKS[0:5] => [0, 61, 185, 40, 39]    \n",
    "    \n",
    "    # tf.gather(x,ref_point,axis=1) => Tensor(\"GatherV2:0\", shape=(None, 118, 3), dtype=float32)\n",
    "    # tf.gather => Gather slices from axis according to indices. Here, ref_point are indices.\n",
    "    # tf.math.is_nan => return Tensor of type bool with \"True\" value at \"nan\" positions.\n",
    "    \n",
    "    # tf.reduce_all(tf.math.is_nan(tf.gather(x,ref_point,axis=1)), axis=[-2,-1]) => Tensor(\"All:0\", shape=(None,), dtype=bool)    \n",
    "    # one of the result from print(tf.reduce_all(tf.math.is_nan(tf.gather(x,ref_point,axis=1)), axis=[-2,-1])) =>\n",
    "    # tf.Tensor([False False False False False False False False False False False False], shape=(12,), dtype=bool)\n",
    "    \n",
    "    # tf.reduce_all => perform tf.math.logical_and (logical and) operation along the axis.\n",
    "    # axis=[-2,-1] => for 3d (x,y,z) tensor, first apply operation to the z-axis elements to reduce them i.e., multiply all z-axis elements. z-axis finished and only x,y axis remains.\n",
    "    #              => second apply operation to the y-axis elements i.e., multiply all y-axis elements. y-axis finished and only x axis remains.\n",
    "\n",
    "\n",
    "    # mask returns False for the sequence where all the 543*3=1629 elements have nan values.\n",
    "    mask = tf.math.logical_not(tf.reduce_all(tf.math.is_nan(tf.gather(x,ref_point,axis=1)), axis=[-2,-1]))\n",
    "    # one of the result from print(mask) =>\n",
    "    # tf.Tensor([ True  True  True  True  True  True  True  True  True  True  True  True], shape=(12,), dtype=bool)\n",
    "    \n",
    "    # remove that sequence from x which have all 1629 values as nan.\n",
    "    x = tf.boolean_mask(x, mask, axis=0)\n",
    "    return x\n",
    "\n",
    "def preprocess(x, augment=False, max_len=MAX_LEN):\n",
    "    # max_len => 64\n",
    "    coord = x['coordinates']    \n",
    "    coord = filter_nans_tf(coord)\n",
    "    if augment:\n",
    "        coord = augment_fn(coord, max_len=max_len)\n",
    "        \n",
    "    # tf.errors.InvalidArgumentError => If shape is incompatible with the shape of x.\n",
    "    coord = tf.ensure_shape(coord, (None, ROWS_PER_FRAME, 3))\n",
    "    \n",
    "    return tf.cast(Preprocess(max_len=max_len)(coord)[0],tf.float32), tf.one_hot(x['sign'], NUM_CLASSES)\n",
    "\n",
    "\n",
    "# def augment_fn(x, always=False, max_len=None):\n",
    "#     if tf.random.uniform(())<0.8 or always:\n",
    "#         x = resample(x, (0.5,1.5))\n",
    "#         # x.shape => (108, 543, 3)\n",
    "#     if tf.random.uniform(())<0.5 or always:\n",
    "#         x = flip_lr(x)        \n",
    "#     if max_len is not None:\n",
    "#         x = temporal_crop(x, max_len)        \n",
    "#     if tf.random.uniform(())<0.75 or always:\n",
    "#         x = spatial_random_affine(x)\n",
    "#     if tf.random.uniform(())<0.5 or always:\n",
    "#         x = temporal_mask(x)\n",
    "#     if tf.random.uniform(())<0.5 or always:\n",
    "#         x = spatial_mask(x)\n",
    "#     return x\n",
    "\n",
    "def augment_fn(x, always=False, max_len=None):\n",
    "    # tf.random.uniform(()) => outputs random values from a uniform distribution in the range [0, 1).    \n",
    "    # tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.dtypes.float32)\n",
    "\n",
    "    if tf.random.uniform(())<0.75 or always:#0.8\n",
    "        x = resample(x, (0.5,1.5))\n",
    "        # x.shape => (108, 543, 3)\n",
    "    if tf.random.uniform(())<0.5 or always:\n",
    "        x = flip_lr(x)\n",
    "        \n",
    "    if max_len is not None:\n",
    "        x = temporal_crop(x, max_len)\n",
    "        \n",
    "    x = random.choice([spatial_random_affine(x) if tf.random.uniform(())<0.75 or always else x,\n",
    "                  temporal_mask(x) if tf.random.uniform(())<0.6 or always else x,#0.5\n",
    "                  spatial_mask(x) if tf.random.uniform(())<0.6 or always else x])#0.5    \n",
    "    return x\n",
    "\n",
    "def spatial_mask(x, size=(0.2,0.4), mask_value=float('nan')):\n",
    "    mask_offset_y = tf.random.uniform(())\n",
    "    mask_offset_x = tf.random.uniform(())\n",
    "    mask_size = tf.random.uniform((), *size)\n",
    "    # x[...,0] => select first channel\n",
    "    # x.shape, x[...,0].shape => (114, 543, 3), (114, 543)\n",
    "    # x[...,1] => select second channel\n",
    "    # x[...,1].shape => (114, 543)\n",
    "    # mask_offset_x, mask_offset_y, mask_size) => tf.Tensor(0.8403015, ...), tf.Tensor(0.33487928, ...), tf.Tensor(0.34486762, ...)    \n",
    "    # (mask_offset_x<x[...,0]) => tensor of True,False. True where \"first channel ()\" values are greater than mask_offset_x.\n",
    "    mask_x = (mask_offset_x<x[...,0]) & (x[...,0] < mask_offset_x + mask_size)\n",
    "    mask_y = (mask_offset_y<x[...,1]) & (x[...,1] < mask_offset_y + mask_size)\n",
    "    mask = mask_x & mask_y\n",
    "    # mask.shape, mask[...,None].shape => (114, 543), (114, 543, 1)\n",
    "    # tf.where(condition, x=None, y=None,) => select x for \"row in condition with value True\" otherwise y. \n",
    "    # suppose 5th row in mask[...,None] is True i.e. (5th, 543, 1) = [True] then all the 3 channel in x corresponding to 5th row have nan values i.e. (5th, 543, 3) = [nan, nan, nan].\n",
    "    x = tf.where(mask[...,None], mask_value, x)\n",
    "    return x\n",
    "\n",
    "def temporal_mask(x, size=(0.2,0.4), mask_value=float('nan')):\n",
    "    l = tf.shape(x)[0]\n",
    "    mask_size = tf.random.uniform((), *size)\n",
    "    mask_size = tf.cast(tf.cast(l, tf.float32) * mask_size, tf.int32)\n",
    "    mask_offset = tf.random.uniform((), 0, tf.clip_by_value(l-mask_size,1,l), dtype=tf.int32)\n",
    "    # tf.range(start, limit, delta=1, dtype=None,) => creates a sequence of numbers.\n",
    "    # tf.range(mask_offset, mask_offset+mask_size)[...,None].shape => (33, 1) => sequence of values from 17 to 49\n",
    "    # tf.fill(dims, value,) => creates a tensor filled with a scalar value.\n",
    "    # tf.fill([mask_size,543,3],mask_value).shape => (33, 543, 3)\n",
    "    x = tf.tensor_scatter_nd_update(x, tf.range(mask_offset, mask_offset+mask_size)[...,None], tf.fill([mask_size,543,3],mask_value))\n",
    "    return x\n",
    "\n",
    "\n",
    "def spatial_random_affine(xyz, scale  = (0.8,1.2), shear = (-0.15,0.15), shift  = (-0.1,0.1), degree = (-30,30),):\n",
    "    '''\n",
    "    Oneof([scale + shear_x + shift + degree, scale + shear_y + shift + degree])\n",
    "    '''\n",
    "    center = tf.constant([0.5,0.5])\n",
    "    if scale is not None:\n",
    "        scale = tf.random.uniform((),*scale)# minval=0.8, maxval=1.2,\n",
    "        # scale => tf.Tensor(0.9771392, shape=(), dtype=float32)\n",
    "        xyz = scale*xyz\n",
    "\n",
    "    if shear is not None:\n",
    "        # xyz.shape => (114, 543, 3)\n",
    "        xy = xyz[...,:2]\n",
    "        # xy.shape => (114, 543, 2)\n",
    "        z = xyz[...,2:]\n",
    "        # z.shape => (114, 543, 1)\n",
    "        shear_x = shear_y = tf.random.uniform((),*shear)\n",
    "        if tf.random.uniform(()) < 0.5:\n",
    "            shear_x = 0.\n",
    "        else:\n",
    "            shear_y = 0.\n",
    "        shear_mat = tf.identity([\n",
    "            [1.,shear_x],\n",
    "            [shear_y,1.]\n",
    "        ])\n",
    "        # shear_mat.shape => (2, 2)\n",
    "        # xy @ shear_mat => performs matrix multiplication.\n",
    "        xy = xy @ shear_mat\n",
    "        # xy.shape => (114, 543, 2)\n",
    "        center = center + [shear_y, shear_x]\n",
    "        # center => tf.Tensor([0.5        0.63269997], shape=(2,), dtype=float32)\n",
    "        xyz = tf.concat([xy,z], axis=-1)\n",
    "\n",
    "    if degree is not None:\n",
    "        xy = xyz[...,:2]\n",
    "        z = xyz[...,2:]\n",
    "        xy -= center\n",
    "        degree = tf.random.uniform((),*degree)\n",
    "        radian = degree/180*np.pi\n",
    "        c = tf.math.cos(radian)\n",
    "        s = tf.math.sin(radian)\n",
    "        rotate_mat = tf.identity([\n",
    "            [c,s],\n",
    "            [-s, c],\n",
    "        ])\n",
    "        xy = xy @ rotate_mat\n",
    "        xy = xy + center\n",
    "        xyz = tf.concat([xy,z], axis=-1)\n",
    "\n",
    "    if shift is not None:\n",
    "        shift = tf.random.uniform((),*shift)\n",
    "        xyz = xyz + shift\n",
    "\n",
    "    return xyz\n",
    "\n",
    "def temporal_crop(x, length=MAX_LEN):\n",
    "    ''' \n",
    "        if x.shape[0]>length then crop it such that equals to length (64). otherwise leave as it is.\n",
    "    '''\n",
    "    # length, x.shape => 64, (13, 543, 3)\n",
    "    l = tf.shape(x)[0]\n",
    "    # tf.clip_by_value( t, clip_value_min, clip_value_max) => clips tensor values to a specified min and max.\n",
    "    # print()\n",
    "    # l-length, tf.clip_by_value(l-length,1,length) => tf.Tensor(-51, shape=(), dtype=int32) tf.Tensor(1, shape=(), dtype=int32)\n",
    "    offset = tf.random.uniform((), 0, tf.clip_by_value(l-length,1,length), dtype=tf.int32)\n",
    "    # offset => tf.Tensor(0, shape=(), dtype=int32)\n",
    "    x = x[offset:offset+length]\n",
    "    # x.shape => (13, 543, 3)\n",
    "    return x\n",
    "\n",
    "def resample(x, rate=(0.8,1.2)):\n",
    "    rate = tf.random.uniform((), rate[0], rate[1])\n",
    "    length = tf.shape(x)[0]\n",
    "    \n",
    "    # tf.cast => casts a tensor to the new \"dtype\".\n",
    "    new_size = tf.cast(rate*tf.cast(length,tf.float32), tf.int32)\n",
    "    new_x = interp1d_(x, new_size)\n",
    "    return new_x\n",
    "\n",
    "\n",
    "def flip_lr(x):    \n",
    "    # tf.rank(x) => tf.Tensor(3, shape=(), dtype=int32)\n",
    "    # rank of a tensor is not the same as the rank of a matrix. rank of a tensor is the number of indices required to uniquely select each element of the tensor. rank is also known as \"order\", \"degree\", or \"ndims.\"\n",
    "    # tf.unstack => unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
    "    # x.shape => (114, 543, 3)\n",
    "    x,y,z = tf.unstack(x, axis=-1)\n",
    "    # first channel is assigned to x. \n",
    "    # second channel is assigned to y.\n",
    "    # third channel is assigned to z.  \n",
    "    # x =>\n",
    "    # tf.Tensor(\n",
    "    # [[0.556084   0.5560475  0.55326635 ... 0.07412859 0.08606292 0.08261177]\n",
    "    #  ...\n",
    "    #  [0.53782934 0.53799355 0.536394   ... 0.09553233 0.11297897 0.11702023]], shape=(114, 543), dtype=float32)  \n",
    "    # y => tf.Tensor([[0.60222936 ... ]], shape=(114, 543), dtype=float32)\n",
    "    # z => tf.Tensor([[-0.04718564 ... ]], shape=(114, 543), dtype=float32)\n",
    "    \n",
    "    x = 1-x    \n",
    "    new_x = tf.stack([x,y,z], -1)\n",
    "    # new_x.shape => (114, 543, 3)\n",
    "    new_x = tf.transpose(new_x, [1,0,2])\n",
    "    # new_x.shape => (543, 114, 3)\n",
    "    \n",
    "    lhand = tf.gather(new_x, LHAND, axis=0)# len(LHAND) => 21, lhand.shape => (21, 114, 3)\n",
    "    rhand = tf.gather(new_x, RHAND, axis=0)# rhand.shape => (21, 114, 3)\n",
    "    # tf.constant(LHAND)[...,None].shape => (21, 1)\n",
    "    # tf.tensor_scatter_nd_update(tensor, indices, updates) => scatter \"updates\" into an existing tensor according to \"indices\".\n",
    "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LHAND)[...,None], rhand)\n",
    "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RHAND)[...,None], lhand)\n",
    "    \n",
    "    llip = tf.gather(new_x, LLIP, axis=0)\n",
    "    rlip = tf.gather(new_x, RLIP, axis=0)\n",
    "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LLIP)[...,None], rlip)\n",
    "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RLIP)[...,None], llip)\n",
    "    \n",
    "    lpose = tf.gather(new_x, LPOSE, axis=0)\n",
    "    rpose = tf.gather(new_x, RPOSE, axis=0)\n",
    "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LPOSE)[...,None], rpose)\n",
    "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RPOSE)[...,None], lpose)\n",
    "    \n",
    "    leye = tf.gather(new_x, LEYE, axis=0)\n",
    "    reye = tf.gather(new_x, REYE, axis=0)\n",
    "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LEYE)[...,None], reye)\n",
    "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(REYE)[...,None], leye)\n",
    "    \n",
    "    lnose = tf.gather(new_x, LNOSE, axis=0)\n",
    "    rnose = tf.gather(new_x, RNOSE, axis=0)\n",
    "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LNOSE)[...,None], rnose)\n",
    "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RNOSE)[...,None], lnose)\n",
    "    \n",
    "    new_x = tf.transpose(new_x, [1,0,2])\n",
    "    # new_x.shape => (114, 543, 3)\n",
    "    return new_x\n",
    "\n",
    "\n",
    "def get_tfrec_dataset(tfrecords, batch_size=64, max_len=64, drop_remainder=False, augment=False, shuffle=False, repeat=False):\n",
    "    # Initialize dataset with TFRecords\n",
    "    ds = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=tf.data.AUTOTUNE, compression_type='GZIP')    \n",
    "    ds = ds.map(decode_tfrec, tf.data.AUTOTUNE)\n",
    "    \n",
    "#     # for debugging\n",
    "#     for x in ds:\n",
    "#         preprocess(x, augment=augment, max_len=max_len)\n",
    "#         break    \n",
    "    ds = ds.map(lambda x: preprocess(x, augment=augment, max_len=max_len), tf.data.AUTOTUNE)\n",
    "\n",
    "    if repeat: \n",
    "        # dataset be repeated indefinitely.\n",
    "        ds = ds.repeat()\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle)\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_deterministic = (False)\n",
    "        ds = ds.with_options(options)\n",
    "    \n",
    "    if batch_size:\n",
    "        # PAD = -100., NUM_CLASSES  = 250, CHANNELS = 708\n",
    "        # padded_batch(batch_size, padded_shapes=None, padding_values=None, drop_remainder=False,) => combines consecutive elements of the dataset into padded batches.\n",
    "        # padded_shapes => shape to which the respective component of each input element should be padded prior to batching.\n",
    "        # drop_remainder => whether the last batch should be dropped in the case it has fewer than batch_size elements.\n",
    "        ds = ds.padded_batch(batch_size, padding_values=PAD, padded_shapes=([max_len,CHANNELS],[NUM_CLASSES]), drop_remainder=drop_remainder)\n",
    "\n",
    "    # prefetch( buffer_size,) => prefetches elements from the dataset. allows later elements to be prepared while the current element is being processed.\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 20:09:36.059370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-29 20:09:36.059552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-29 20:09:36.059655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-29 20:09:36.526820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-29 20:09:36.527004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-29 20:09:36.527113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-29 20:09:36.527191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5662 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "ds = get_tfrec_dataset(TRAIN_FILENAMES[0:1], batch_size=1024, augment=True) # TRAIN_FILENAMES[0:1] => ['islr_records/fold3-5-512.tfrecords']\n",
    "# ds = get_tfrec_dataset(TRAIN_FILENAMES, augment=True, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 20:09:37.765530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-29 20:09:37.765829: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "# this cell show response when you have declared: tf.compat.v1.enable_eager_execution() and tf.data.experimental.enable_debug_mode()\n",
    "# for detailed view of tensor instead of symbolic view i.e. for debugging.\n",
    "for x in ds:\n",
    "    temp_train = x\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:52:04.005070Z",
     "iopub.status.busy": "2023-05-23T01:52:04.004607Z",
     "iopub.status.idle": "2023-05-23T01:52:04.394932Z",
     "shell.execute_reply": "2023-05-23T01:52:04.393857Z",
     "shell.execute_reply.started": "2023-05-23T01:52:04.005039Z"
    },
    "id": "gbVSTH9xqAFQ",
    "outputId": "c212e69c-230c-4ded-b204-183dd28eebcb"
   },
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# import matplotlib.animation as animation\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# def filter_nans(frames):\n",
    "#     return frames[~np.isnan(frames).all(axis=(-2,-1))]\n",
    "\n",
    "# ds = tf.data.TFRecordDataset(TRAIN_FILENAMES, num_parallel_reads=tf.data.AUTOTUNE, compression_type='GZIP')\n",
    "# ds = ds.map(decode_tfrec, tf.data.AUTOTUNE)\n",
    "# print(ds)\n",
    "# for x in ds:\n",
    "#     temp = x['coordinates'].numpy()\n",
    "#     if not len(filter_nans(temp[:,LHAND])) == 0:\n",
    "#         break\n",
    "    \n",
    "# edges = [(0,1),(1,2),(2,3),(3,4),(0,5),(0,17),(5,6),(6,7),(7,8),(5,9),(9,10),(10,11),(11,12),\n",
    "#          (9,13),(13,14),(14,15),(15,16),(13,17),(17,18),(18,19),(19,20)]\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# def plot_frame(frame, edges=[], idxs=[]):\n",
    "        \n",
    "#     frame[np.isnan(frame)] = 0\n",
    "#     x = list(frame[...,0])\n",
    "#     y = list(frame[...,1])\n",
    "#     if len(idxs) == 0:\n",
    "#         idxs = list(range(len(x)))\n",
    "#     ax.clear()\n",
    "#     ax.scatter(x, y, color='dodgerblue')\n",
    "#     for i in range(len(x)):\n",
    "#         ax.text(x[i], y[i], idxs[i])\n",
    "        \n",
    "#     for edge in edges:\n",
    "#         ax.plot([x[edge[0]], x[edge[1]]], [y[edge[0]], y[edge[1]]], color='salmon')\n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_yticks([])\n",
    "#     ax.set_xticklabels([])\n",
    "#     ax.set_yticklabels([])\n",
    "\n",
    "# def animate_frames(frames, edges=[], idxs=[]):\n",
    "#     anim = FuncAnimation(fig, lambda frame: plot_frame(frame, edges, idxs), frames=frames, interval=100)\n",
    "#     return HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:52:04.396635Z",
     "iopub.status.busy": "2023-05-23T01:52:04.396142Z",
     "iopub.status.idle": "2023-05-23T01:52:04.400515Z",
     "shell.execute_reply": "2023-05-23T01:52:04.399572Z",
     "shell.execute_reply.started": "2023-05-23T01:52:04.396604Z"
    },
    "id": "ElHcJ18fqAFQ",
    "outputId": "b33692c7-b86a-4a2e-b341-e723ee9e6ff6"
   },
   "outputs": [],
   "source": [
    "# Animate the frames\n",
    "# animate_frames(filter_nans(temp[:,LHAND]),edges=edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:52:04.402039Z",
     "iopub.status.busy": "2023-05-23T01:52:04.401644Z",
     "iopub.status.idle": "2023-05-23T01:52:04.411917Z",
     "shell.execute_reply": "2023-05-23T01:52:04.411081Z",
     "shell.execute_reply.started": "2023-05-23T01:52:04.402009Z"
    },
    "id": "mWgeoL42qAFQ",
    "outputId": "2b45c04a-ba4a-4de5-a202-575dd42ed3bd"
   },
   "outputs": [],
   "source": [
    "# animate_frames(filter_nans(augment_fn(temp,always=True).numpy()[:,RHAND]),edges=edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:52:04.413325Z",
     "iopub.status.busy": "2023-05-23T01:52:04.413026Z",
     "iopub.status.idle": "2023-05-23T01:52:04.421977Z",
     "shell.execute_reply": "2023-05-23T01:52:04.421198Z",
     "shell.execute_reply.started": "2023-05-23T01:52:04.413299Z"
    },
    "id": "PTiGFv8aqAFQ",
    "outputId": "46cca07d-5352-4895-c433-b79823c45acd"
   },
   "outputs": [],
   "source": [
    "# animate_frames(filter_nans(temp[:,POINT_LANDMARKS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:52:04.423291Z",
     "iopub.status.busy": "2023-05-23T01:52:04.422991Z",
     "iopub.status.idle": "2023-05-23T01:52:04.432030Z",
     "shell.execute_reply": "2023-05-23T01:52:04.431208Z",
     "shell.execute_reply.started": "2023-05-23T01:52:04.423266Z"
    },
    "id": "AAoOqgRKqAFQ",
    "outputId": "a7be0446-245e-4335-a2d0-913901d17c3e"
   },
   "outputs": [],
   "source": [
    "# animate_frames(filter_nans(augment_fn(temp,always=True).numpy()[:,POINT_LANDMARKS]), idxs=POINT_LANDMARKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:52:04.433493Z",
     "iopub.status.busy": "2023-05-23T01:52:04.433110Z",
     "iopub.status.idle": "2023-05-23T01:52:04.462408Z",
     "shell.execute_reply": "2023-05-23T01:52:04.461613Z",
     "shell.execute_reply.started": "2023-05-23T01:52:04.433467Z"
    },
    "id": "zaIHc89AqAFQ"
   },
   "outputs": [],
   "source": [
    "class ECA(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    ECA (stands for Efficient Channel Attention)\n",
    "    This layer applies channel attention to the input tensor by calculating a channel-wise attention map and multiplying it element-wise with the input.\n",
    "    Technique used to enhance the representation power of deep neural networks, particularly in computer vision tasks. \n",
    "    This operation effectively applies channel attention to the input, emphasizing important channels and suppressing less relevant ones.\n",
    "    Channels that carry more relevant information for the task at hand will have higher attention weights, while channels with less useful information will have lower weights. \n",
    "    '''\n",
    "    def __init__(self, kernel_size=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = tf.keras.layers.Conv1D(1, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=False)\n",
    "        \n",
    "    def call(self, inputs, mask=None):\n",
    "        # inputs.shape => (512, 64, 384)\n",
    "        # GlobalAveragePooling1D() => global average pooling over the spatial dimensions of the input tensor to generate a single value per channel.\n",
    "        nn = tf.keras.layers.GlobalAveragePooling1D()(inputs, mask=mask)\n",
    "        # nn.shape => (512, 384)\n",
    "        nn = tf.expand_dims(nn, -1)\n",
    "        # nn.shape => (512, 384, 1)\n",
    "        # 1D convolutional operation is applied independently to each channel.\n",
    "        nn = self.conv(nn)\n",
    "        # nn.shape => (512, 384, 1)\n",
    "        nn = tf.squeeze(nn, -1)\n",
    "        # nn.shape => (512, 384)\n",
    "        nn = tf.nn.sigmoid(nn)\n",
    "        # nn.shape => (512, 384)\n",
    "        # adds a new dimension at the second axis.\n",
    "        nn = nn[:,None,:]\n",
    "        # nn.shape => (512, 1, 384)\n",
    "        \n",
    "        # (inputs * nn).shape => (512, 64, 384)\n",
    "        # element wise multiplication is performed by expanded (512,1,64) along the second dimension (from 1 to 64) so that its shape becomes (512, 64, 384). \n",
    "        return inputs * nn\n",
    "\n",
    "class LateDropout(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        This layer implements dropout regularization but delays its effect until a specified training step.    \n",
    "    '''\n",
    "    def __init__(self, rate, noise_shape=None, start_step=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.rate = rate\n",
    "        self.start_step = start_step\n",
    "        self.dropout = tf.keras.layers.Dropout(rate, noise_shape=noise_shape)\n",
    "      \n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        # tf.VariableAggregation => indicates how a distributed variable will be aggregated.\n",
    "        agg = tf.VariableAggregation.ONLY_FIRST_REPLICA\n",
    "        self._train_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg, trainable=False)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # tf.cond(pred, true_fn=None, false_fn=None,) => return true_fn() if the predicate pred is true else false_fn().\n",
    "        # if self._train_counter and self.start_step are equal then false_fn is executed.\n",
    "        x = tf.cond(self._train_counter < self.start_step, lambda:inputs, lambda:self.dropout(inputs, training=training))\n",
    "        if training:\n",
    "            self._train_counter.assign_add(1)\n",
    "        return x\n",
    "\n",
    "class CausalDWConv1D(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        1-dimensional depthwise convolutional layer with causal padding. \n",
    "    '''\n",
    "    def __init__(self, \n",
    "        kernel_size=17,\n",
    "        dilation_rate=1,\n",
    "        use_bias=False,\n",
    "        depthwise_initializer='glorot_uniform',\n",
    "        name='', **kwargs):\n",
    "        super().__init__(name=name,**kwargs)        \n",
    "        # tf.keras.layers.ZeroPadding1D( (left_pad, right_pad),) => how many zeros to add at the left and right of the \"padding dimension (axis 1)\".\n",
    "        # ...,0) => no zeros should be added at right (future) of the padding dimension.\n",
    "        # Causal padding by introducing padding only to the left (past) side of the input sequence, ensuring that the convolution operation does not have access to future information during the forward pass.\n",
    "        self.causal_pad = tf.keras.layers.ZeroPadding1D((dilation_rate*(kernel_size-1),0),name=name + '_pad')\n",
    "        self.dw_conv = tf.keras.layers.DepthwiseConv1D(\n",
    "                            kernel_size,\n",
    "                            strides=1,\n",
    "                            dilation_rate=dilation_rate,\n",
    "                            padding='valid',\n",
    "                            use_bias=use_bias,\n",
    "                            depthwise_initializer=depthwise_initializer,\n",
    "                            name=name + '_dwconv')\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # inputs.shape => (512, 64, 384)\n",
    "        x = self.causal_pad(inputs)\n",
    "        # x.shape => (512, 80, 384)\n",
    "        x = self.dw_conv(x)\n",
    "        # x.shape => (512, 64, 384)        \n",
    "        return x\n",
    "\n",
    "def Conv1DBlock(channel_size,\n",
    "          kernel_size,\n",
    "          dilation_rate=1,\n",
    "          drop_rate=0.0,\n",
    "          expand_ratio=2,# the expansion ratio for the dense layer.\n",
    "          se_ratio=0.25,# the squeeze-and-excitation ratio. \n",
    "          activation='swish',\n",
    "          name=None):\n",
    "    '''\n",
    "    efficient conv1d block, @hoyso48\n",
    "    '''\n",
    "    if name is None:\n",
    "        # tf.keras.backend.get_uid(prefix='') => associates a string prefix with an integer counter in a TensorFlow graph.  uid (Unique integer ID).\n",
    "        # name parameter is not provided, the function generates a unique name for the convolutional block by prefixing the uid.\n",
    "        name = str(tf.keras.backend.get_uid(\"mbblock\"))\n",
    "        \n",
    "    # Expansion phase\n",
    "    def apply(inputs):\n",
    "        # tf.keras.backend.int_shape(x) => returns shape of tensor/variable as a tuple of int/None entries. x: Tensor or variable.\n",
    "        channels_in = tf.keras.backend.int_shape(inputs)[-1]\n",
    "        \n",
    "        # nodes/units of the dense layer.\n",
    "        channels_expand = channels_in * expand_ratio\n",
    "\n",
    "        skip = inputs\n",
    "\n",
    "        x = tf.keras.layers.Dense(\n",
    "            channels_expand,\n",
    "            use_bias=True,\n",
    "            activation=activation,\n",
    "            name=name + '_expand_conv')(inputs)\n",
    "\n",
    "        # Depthwise Convolution\n",
    "        x = CausalDWConv1D(kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            use_bias=False,\n",
    "            name=name + '_dwconv')(x)\n",
    "        \n",
    "        # \"momentum\" parameter refers to the \"exponential moving average (EMA)\" decay factor used to update the \"moving_mean\" and \"moving_variance\" statistics during training.\n",
    "        # momentum value is to adjust the influence of individual mini-batches mean and variance (which can exhibit high variability) in \"moving_mean\" and \"moving_variance\".\n",
    "        # \"moving_mean\" and \"moving_variance\" and used during inference instead of individual mini-batche mean and variance.\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95, name=name + '_bn')(x)\n",
    "\n",
    "        x  = ECA()(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(\n",
    "            channel_size,\n",
    "            use_bias=True,\n",
    "            name=name + '_project_conv')(x)\n",
    "\n",
    "        if drop_rate > 0:\n",
    "            x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1), name=name + '_drop')(x)\n",
    "\n",
    "        if (channels_in == channel_size):\n",
    "            x = tf.keras.layers.add([x, skip], name=name + '_add')\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:52:04.463751Z",
     "iopub.status.busy": "2023-05-23T01:52:04.463447Z",
     "iopub.status.idle": "2023-05-23T01:52:04.483238Z",
     "shell.execute_reply": "2023-05-23T01:52:04.482379Z",
     "shell.execute_reply.started": "2023-05-23T01:52:04.463710Z"
    },
    "id": "8hPmJX0YqAFR"
   },
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim=256, num_heads=4, dropout=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.scale = self.dim ** -0.5\n",
    "        self.num_heads = num_heads\n",
    "        self.qkv = tf.keras.layers.Dense(3 * dim, use_bias=False)\n",
    "        self.drop1 = tf.keras.layers.Dropout(dropout)\n",
    "        self.proj = tf.keras.layers.Dense(dim, use_bias=False)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        # inputs.shape => (512, 64, 192)\n",
    "        # qkv i.e., query, key, value\n",
    "        qkv = self.qkv(inputs)\n",
    "        # qkv.shape => (512, 64, 576)\n",
    "        \n",
    "        # tf.keras.layers.Permute(dims, **kwargs) => permutes the dimensions of the input according to a given pattern.\n",
    "        # tf.keras.layers.Reshape(target_shape=?) => layer that reshapes inputs into the given shape.\n",
    "        qkv = tf.keras.layers.Permute((2, 1, 3))(tf.keras.layers.Reshape((-1, self.num_heads, self.dim * 3 // self.num_heads))(qkv))\n",
    "        # qkv.shape => (512, 4, 64, 144)\n",
    "        \n",
    "        \n",
    "        # tf.split(value, num_or_size_splits, axis=0, num=None,) => splits a tensor value into a list of sub tensors.\n",
    "        # split qkv along dimension -1.\n",
    "        q, k, v = tf.split(qkv, [self.dim // self.num_heads] * 3, axis=-1)\n",
    "        # q.shape, k.shape, v.shape => (512, 4, 64, 48), (512, 4, 64, 48), (512, 4, 64, 48)\n",
    "        \n",
    "        attn = tf.matmul(q, k, transpose_b=True) * self.scale\n",
    "        # attn.shape => (512, 4, 64, 64)\n",
    "        \n",
    "\n",
    "        if mask is not None:\n",
    "            # mask.shape => (512, 64)\n",
    "            mask = mask[:, None, None, :]\n",
    "            # mask.shape => (512, 1, 1, 64)\n",
    "\n",
    "        # axis=-1 => axis along which the softmax normalization is applied.\n",
    "        # ..., mask=mask) => mask certain positions in the input tensor before applying the softmax function.\n",
    "        # the softmax of each vector x is computed as \"exp(x) / tf.reduce_sum(exp(x))\".\n",
    "        # apply softmax over 64 classes (present in last dimension) for each 64 rows (present in 3rd dimension).        \n",
    "        attn = tf.keras.layers.Softmax(axis=-1)(attn, mask=mask)\n",
    "        # attn.shape => (512, 4, 64, 64)\n",
    "        \n",
    "        attn = self.drop1(attn)\n",
    "\n",
    "        # @ => matrix multiplication.\n",
    "        x = attn @ v\n",
    "        # x.shape => (512, 4, 64, 48)\n",
    "        \n",
    "        x = tf.keras.layers.Reshape((-1, self.dim))(tf.keras.layers.Permute((2, 1, 3))(x))\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def TransformerBlock(dim=256, num_heads=4, expand=4, attn_dropout=0.2, drop_rate=0.2, activation='swish'):\n",
    "    def apply(inputs):\n",
    "        x = inputs\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95)(x)\n",
    "        x = MultiHeadSelfAttention(dim=dim,num_heads=num_heads,dropout=attn_dropout)(x)\n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        # tf.keras.layers.Add => layer that adds a list of inputs.\n",
    "        x = tf.keras.layers.Add()([inputs, x])\n",
    "        attn_out = x\n",
    "\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95)(x)\n",
    "        x = tf.keras.layers.Dense(dim*expand, use_bias=False, activation=activation)(x)\n",
    "        x = tf.keras.layers.Dense(dim, use_bias=False)(x)\n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        x = tf.keras.layers.Add()([attn_out, x])\n",
    "        return x\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:52:04.484583Z",
     "iopub.status.busy": "2023-05-23T01:52:04.484289Z",
     "iopub.status.idle": "2023-05-23T01:52:08.852365Z",
     "shell.execute_reply": "2023-05-23T01:52:08.851295Z",
     "shell.execute_reply.started": "2023-05-23T01:52:04.484560Z"
    },
    "id": "KIooIcnSqAFR",
    "outputId": "4d6a1f52-1630-45d6-a33c-441aab02d1b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 20:09:40.017050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-29 20:09:40.138844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.5783253>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model(max_len=64, dropout_step=0, dim=192):\n",
    "    inp = tf.keras.Input((max_len,CHANNELS))\n",
    "    \n",
    "    # tf.keras.layers.Masking(mask_value=0.0, **kwargs) => masks a sequence by using a mask value to skip timesteps.\n",
    "    x = tf.keras.layers.Masking(mask_value=PAD,input_shape=(max_len,CHANNELS))(inp)\n",
    "    ksize = 17\n",
    "    x = tf.keras.layers.Dense(dim, use_bias=False,name='stem_conv')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(momentum=0.95,name='stem_bn')(x)\n",
    "\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "    x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "    if dim == 384: #for the 4x sized model\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n",
    "        x = TransformerBlock(dim,expand=2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(dim*2,activation=None,name='top_conv')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = LateDropout(0.8, start_step=dropout_step)(x)# dropout_rate = 0.8\n",
    "    x = tf.keras.layers.Dense(NUM_CLASSES,name='classifier')(x)\n",
    "    return tf.keras.Model(inp, x)\n",
    "\n",
    "model = get_model()\n",
    "# temp_train[0].shape => (512, 64, 708), \n",
    "# one hot encoded output temp_train[1] with shape (512, 250).\n",
    "y = model(temp_train[0])\n",
    "tf.keras.losses.CategoricalCrossentropy(from_logits=True)(temp_train[1],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph - visual plot\n",
    "# tf.keras.utils.plot_model(model, to_file=\"model.png\", expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:52:08.853948Z",
     "iopub.status.busy": "2023-05-23T01:52:08.853563Z",
     "iopub.status.idle": "2023-05-23T01:52:08.858641Z",
     "shell.execute_reply": "2023-05-23T01:52:08.857715Z",
     "shell.execute_reply.started": "2023-05-23T01:52:08.853922Z"
    },
    "id": "Nui7lZmUqAFR"
   },
   "outputs": [],
   "source": [
    "#check supports_masking\n",
    "for x in model.layers:\n",
    "    if not x.supports_masking:\n",
    "        print(x.supports_masking, x.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:52:08.860316Z",
     "iopub.status.busy": "2023-05-23T01:52:08.859990Z",
     "iopub.status.idle": "2023-05-23T01:52:08.892604Z",
     "shell.execute_reply": "2023-05-23T01:52:08.891802Z",
     "shell.execute_reply.started": "2023-05-23T01:52:08.860288Z"
    },
    "id": "BoGUEL6-oEWO"
   },
   "outputs": [],
   "source": [
    "def train_fold(CFG, fold, train_files, valid_files=None, strategy=STRATEGY, summary=True):\n",
    "    seed_everything(CFG.seed)\n",
    "    tf.keras.backend.clear_session()\n",
    "    _ = gc.collect()\n",
    "    \n",
    "    # tf.config.optimizer.set_jit(enabled=?) => configure JIT compilation. True to perform autoclustering (automatically identify and compile clusters of nodes) on all graphs using XLA.\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "        \n",
    "    if CFG.fp16:\n",
    "        try:\n",
    "            policy = mixed_precision.Policy('mixed_bfloat16')\n",
    "            mixed_precision.set_global_policy(policy)\n",
    "        except:\n",
    "            policy = mixed_precision.Policy('mixed_float16')\n",
    "            mixed_precision.set_global_policy(policy)\n",
    "    else:\n",
    "        policy = mixed_precision.Policy('float32')\n",
    "        mixed_precision.set_global_policy(policy)\n",
    "\n",
    "    if fold != 'all':\n",
    "        train_ds = get_tfrec_dataset(train_files, batch_size=CFG.batch_size, max_len=CFG.max_len, drop_remainder=True, augment=True, repeat=True, shuffle=32768)\n",
    "        valid_ds = get_tfrec_dataset(valid_files, batch_size=CFG.batch_size, max_len=CFG.max_len, drop_remainder=False, repeat=False, shuffle=False)\n",
    "    else:\n",
    "        train_ds = get_tfrec_dataset(train_files, batch_size=CFG.batch_size, max_len=CFG.max_len, drop_remainder=False, augment=True, repeat=True, shuffle=32768)\n",
    "        valid_ds = None\n",
    "        valid_files = []\n",
    "    \n",
    "    num_train = count_data_items(train_files)\n",
    "    num_valid = count_data_items(valid_files)\n",
    "    steps_per_epoch = num_train//CFG.batch_size\n",
    "    # steps_per_epoch => 1168\n",
    "    \n",
    "    # distribution strategies were introduced to help distribute training across multiple GPUs, multiple machines or TPUs with minimal code changes.\n",
    "    with strategy.scope():\n",
    "        dropout_step = CFG.dropout_start_epoch * steps_per_epoch\n",
    "        model = get_model(max_len=CFG.max_len, dropout_step=dropout_step, dim=CFG.dim)\n",
    "\n",
    "        schedule = OneCycleLR(CFG.lr, CFG.epoch, warmup_epochs=CFG.epoch*CFG.warmup, steps_per_epoch=steps_per_epoch, resume_epoch=CFG.resume, decay_epochs=CFG.epoch, lr_min=CFG.lr_min, decay_type=CFG.decay_type, warmup_type='linear')\n",
    "        decay_schedule = OneCycleLR(CFG.lr*CFG.weight_decay, CFG.epoch, warmup_epochs=CFG.epoch*CFG.warmup, steps_per_epoch=steps_per_epoch, resume_epoch=CFG.resume, decay_epochs=CFG.epoch, lr_min=CFG.lr_min*CFG.weight_decay, decay_type=CFG.decay_type, warmup_type='linear')\n",
    "        \n",
    "        awp_step = CFG.awp_start_epoch * steps_per_epoch\n",
    "        \n",
    "        if CFG.fgm:\n",
    "            model = FGM(model.input, model.output, delta=CFG.awp_lambda, eps=0., start_step=awp_step)\n",
    "        elif CFG.awp:\n",
    "            model = AWP(model.input, model.output, delta=CFG.awp_lambda, eps=0., start_step=awp_step)\n",
    "\n",
    "        # tfa.optimizers.RectifiedAdam => variant of the Adam optimizer whose adaptive learning rate is rectified so as to have a consistent variance.\n",
    "        opt = tfa.optimizers.RectifiedAdam(learning_rate=schedule, weight_decay=decay_schedule, sma_threshold=4)#, clipvalue=1.)\n",
    "        # Lookahead => extend optimizers with the lookahead mechanism. optimizer iteratively updates two sets of weights and and the two sets of weights are synchronized.\n",
    "        opt = tfa.optimizers.Lookahead(opt,sync_period=5)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=opt,\n",
    "            loss=[tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)], #[tf.keras.losses.CategoricalCrossentropy(from_logits=True)],\n",
    "            metrics=[\n",
    "                [\n",
    "                tf.keras.metrics.CategoricalAccuracy(),\n",
    "                ],\n",
    "            ],\n",
    "            steps_per_execution=steps_per_epoch,\n",
    "        )\n",
    "    \n",
    "    if summary:\n",
    "        print()\n",
    "        # model.summary()\n",
    "        print()\n",
    "        print(train_ds, valid_ds)\n",
    "        print()\n",
    "        schedule.plot()\n",
    "        print()\n",
    "        init=False\n",
    "        \n",
    "    print(f'---------fold{fold}---------')\n",
    "    print(f'train:{num_train} valid:{num_valid}')\n",
    "    print()\n",
    "    \n",
    "    if CFG.resume:\n",
    "        print(f'resume from epoch{CFG.resume}')\n",
    "        model.load_weights(f'{CFG.loc}/{CFG.comment}-fold{fold}-best.h5')\n",
    "#         if train_ds is not None:\n",
    "#             # .take(count=?) => creates a Dataset with at most count elements from this dataset.\n",
    "#             model.evaluate(train_ds.take(steps_per_epoch))\n",
    "#         if valid_ds is not None:\n",
    "#             model.evaluate(valid_ds)\n",
    "\n",
    "    logger = tf.keras.callbacks.CSVLogger(f'{CFG.output_dir}/{CFG.comment}-fold{fold}-logs.csv')\n",
    "    sv_loss = tf.keras.callbacks.ModelCheckpoint(f'{CFG.output_dir}/{CFG.comment}-fold{fold}-best.h5', monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                save_weights_only=True, mode='min', save_freq='epoch')\n",
    "    # Snapshot() => save weights at certain epochs and at last of every epoch.\n",
    "    snap = Snapshot(f'{CFG.output_dir}/{CFG.comment}-fold{fold}', CFG.snapshot_epochs)\n",
    "    # SWA = stochastic weight averaging.\n",
    "    swa = SWA(f'{CFG.output_dir}/{CFG.comment}-fold{fold}', CFG.swa_epochs, strategy=strategy, train_ds=train_ds, valid_ds=valid_ds, valid_steps=-(num_valid//-CFG.batch_size))\n",
    "    \n",
    "    callbacks = []    \n",
    "    if CFG.save_output:\n",
    "        callbacks.append(logger)\n",
    "        callbacks.append(snap)\n",
    "        callbacks.append(swa)\n",
    "        if fold != 'all':\n",
    "            callbacks.append(sv_loss)\n",
    "    \n",
    "    \n",
    "    # -(num_valid//-CFG.batch_size), num_valid => 288, 18432\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=CFG.epoch-CFG.resume,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=valid_ds,\n",
    "        verbose=CFG.verbose,\n",
    "        validation_steps=-(num_valid//-CFG.batch_size)\n",
    "    )\n",
    "\n",
    "    if CFG.save_output:\n",
    "        try:\n",
    "            model.load_weights(f'{CFG.output_dir}/{CFG.comment}-fold{fold}-best.h5')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    if fold != 'all':\n",
    "        cv = model.evaluate(valid_ds,verbose=CFG.verbose,steps=-(num_valid//-CFG.batch_size))\n",
    "    else:\n",
    "        cv = None\n",
    "\n",
    "    return model, cv, history\n",
    "\n",
    "def train_folds(CFG, folds, strategy=STRATEGY, summary=True):\n",
    "    for fold in folds:\n",
    "        if fold != 'all':\n",
    "            all_files = TRAIN_FILENAMES\n",
    "            train_files = [x for x in all_files if f'fold{fold}' not in x]\n",
    "            valid_files = [x for x in all_files if f'fold{fold}' in x]\n",
    "        else:\n",
    "            train_files = TRAIN_FILENAMES\n",
    "            valid_files = None\n",
    "        \n",
    "        train_fold(CFG, fold, train_files, valid_files, strategy=strategy, summary=summary)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYUI6mAlqAFR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T01:52:08.893811Z",
     "iopub.status.busy": "2023-05-23T01:52:08.893543Z"
    },
    "id": "V8T5GhYPqAFR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 384, 708), dtype=tf.float32, name=None), TensorSpec(shape=(64, 250), dtype=tf.float32, name=None))> <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 384, 708), dtype=tf.float32, name=None), TensorSpec(shape=(None, 250), dtype=tf.float32, name=None))>\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------fold2---------\n",
      "train:74752 valid:18432\n",
      "\n",
      "288 18432\n",
      "Epoch 1/350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 22:42:52.061267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [146]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-29 22:42:52.061656: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [146]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m CFG\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# train_folds(CFG, [0])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#train_folds(CFG, [1])\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m train_folds(CFG, [\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m      7\u001b[0m train_folds(CFG, [\u001b[38;5;241m4\u001b[39m])\n",
      "Cell \u001b[0;32mIn[32], line 133\u001b[0m, in \u001b[0;36mtrain_folds\u001b[0;34m(CFG, folds, strategy, summary)\u001b[0m\n\u001b[1;32m    130\u001b[0m         train_files \u001b[38;5;241m=\u001b[39m TRAIN_FILENAMES\n\u001b[1;32m    131\u001b[0m         valid_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mtrain_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 100\u001b[0m, in \u001b[0;36mtrain_fold\u001b[0;34m(CFG, fold, train_files, valid_files, strategy, summary)\u001b[0m\n\u001b[1;32m     96\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mappend(sv_loss)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m-\u001b[39m(num_valid\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m-\u001b[39mCFG\u001b[38;5;241m.\u001b[39mbatch_size), num_valid)\n\u001b[0;32m--> 100\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_valid\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CFG\u001b[38;5;241m.\u001b[39msave_output:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    768\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 171\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filedwbdvkor.py:27\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     25\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m _ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py:451\u001b[0m, in \u001b[0;36mfor_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(iter_, distribute\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[1;32m    448\u001b[0m   \u001b[38;5;66;03m# TODO(b/162250181): Use _tf_iterator_for_stmt(iter(iter_)...\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   for_fn \u001b[38;5;241m=\u001b[39m _tf_distributed_iterable_for_stmt\n\u001b[0;32m--> 451\u001b[0m \u001b[43mfor_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43miter_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py:658\u001b[0m, in \u001b[0;36m_tf_range_for_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m    652\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m main_test\n\u001b[1;32m    654\u001b[0m _add_max_iterations_hint(\n\u001b[1;32m    655\u001b[0m     opts,\n\u001b[1;32m    656\u001b[0m     math_ops\u001b[38;5;241m.\u001b[39mcast(misc\u001b[38;5;241m.\u001b[39mget_range_len(start, limit, delta), dtypes\u001b[38;5;241m.\u001b[39mint32))\n\u001b[0;32m--> 658\u001b[0m \u001b[43m_tf_while_stmt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43maug_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43maug_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43maug_get_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43maug_set_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<internal iterate>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msymbol_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py:1137\u001b[0m, in \u001b[0;36m_tf_while_stmt\u001b[0;34m(test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m   1131\u001b[0m   shape_invars_by_init_vals \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1132\u001b[0m       \u001b[38;5;28mid\u001b[39m(v): i \u001b[38;5;28;01mfor\u001b[39;00m v, i \u001b[38;5;129;01min\u001b[39;00m opts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape_invariants\u001b[39m\u001b[38;5;124m'\u001b[39m, ())\n\u001b[1;32m   1133\u001b[0m   }\n\u001b[1;32m   1134\u001b[0m   shape_invariants \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m   1135\u001b[0m       shape_invars_by_init_vals\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mid\u001b[39m(v), \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m orig_init_vars)\n\u001b[1;32m   1136\u001b[0m   (require_one_iteration, init_vars,\n\u001b[0;32m-> 1137\u001b[0m    extra_shape_invariants) \u001b[38;5;241m=\u001b[39m \u001b[43m_try_handling_undefineds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mnulls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_invariants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43msymbol_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1142\u001b[0m   require_one_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py:1077\u001b[0m, in \u001b[0;36m_try_handling_undefineds\u001b[0;34m(body, get_state, set_state, init_vars, nulls, shape_invariants, symbol_names)\u001b[0m\n\u001b[1;32m   1074\u001b[0m   set_state(autocast_init_vars)\n\u001b[1;32m   1075\u001b[0m   state_modified \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1077\u001b[0m   \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m   first_iter_vars \u001b[38;5;241m=\u001b[39m get_state()\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;66;03m# Note: the actual placeholder value doesn't matter, because as the\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;66;03m# staging proved, it will be replaced by an actual value before being\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;66;03m# read.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py:634\u001b[0m, in \u001b[0;36m_tf_range_for_stmt.<locals>.aug_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maug_body\u001b[39m():\n\u001b[1;32m    633\u001b[0m   \u001b[38;5;28;01mnonlocal\u001b[39;00m iterate\n\u001b[0;32m--> 634\u001b[0m   \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m   iterate \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m delta\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filedwbdvkor.py:24\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m outputs\n\u001b[1;32m     23\u001b[0m _ \u001b[38;5;241m=\u001b[39m itr\n\u001b[0;32m---> 24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/keras/engine/training.py:1268\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1264\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1265\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m     )\n\u001b[1;32m   1267\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1268\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1269\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1270\u001b[0m     outputs,\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1272\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1273\u001b[0m )\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1312\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1315\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1316\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2894\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2895\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3696\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3695\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 3696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/keras/engine/training.py:1249\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1249\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/Documents/islr/utils/learners.py:90\u001b[0m, in \u001b[0;36mAWP.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_counter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAWP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step_awp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py:1427\u001b[0m, in \u001b[0;36mcond_for_tf_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcond_for_tf_v2\u001b[39m(pred, true_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, false_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Return `true_fn()` if the predicate `pred` is true else `false_fn()`.\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m \n\u001b[1;32m   1332\u001b[0m \u001b[38;5;124;03m  Note: This op is automatically used in a `tf.function` to convert Python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \n\u001b[1;32m   1426\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:576\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    569\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    570\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    571\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    574\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    575\u001b[0m           instructions)\n\u001b[0;32m--> 576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py:1210\u001b[0m, in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mEnableControlFlowV2(ops\u001b[38;5;241m.\u001b[39mget_default_graph()):\n\u001b[0;32m-> 1210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcond_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m, [pred]):\n\u001b[1;32m   1213\u001b[0m   \u001b[38;5;66;03m# Add the Switch to the graph.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pred, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/ops/cond_v2.py:80\u001b[0m, in \u001b[0;36mcond_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (tensor_util\u001b[38;5;241m.\u001b[39mis_tf_type(pred) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     (pred\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m pred\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mdims)):\n\u001b[1;32m     78\u001b[0m   pred \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39msqueeze_v2(pred)\n\u001b[0;32m---> 80\u001b[0m true_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrue_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCondBranchFuncGraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collections\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_return_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m false_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m     88\u001b[0m     false_name,\n\u001b[1;32m     89\u001b[0m     false_fn, [], {},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m     add_control_dependencies\u001b[38;5;241m=\u001b[39madd_control_dependencies,\n\u001b[1;32m     93\u001b[0m     op_return_value\u001b[38;5;241m=\u001b[39mpred)\n\u001b[1;32m     95\u001b[0m verify_captures(_COND, [true_graph, false_graph])\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/Documents/islr/utils/learners.py:90\u001b[0m, in \u001b[0;36mAWP.train_step.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcond(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_counter \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_step, \u001b[38;5;28;01mlambda\u001b[39;00m:\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAWP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mlambda\u001b[39;00m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step_awp(data))\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/keras/engine/training.py:1054\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1054\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/keras/optimizers/legacy/optimizer_v2.py:588\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03mThis method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    585\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_gradients(\n\u001b[1;32m    586\u001b[0m     loss, var_list\u001b[38;5;241m=\u001b[39mvar_list, grad_loss\u001b[38;5;241m=\u001b[39mgrad_loss, tape\u001b[38;5;241m=\u001b[39mtape\n\u001b[1;32m    587\u001b[0m )\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow_addons/optimizers/lookahead.py:113\u001b[0m, in \u001b[0;36mLookahead.apply_gradients\u001b[0;34m(self, grads_and_vars, name, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39m_iterations \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations\n\u001b[1;32m    112\u001b[0m     )  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/keras/optimizers/legacy/optimizer_v2.py:747\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    744\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_gradients(grads_and_vars)\n\u001b[1;32m    745\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_gradients(grads_and_vars)\n\u001b[0;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_apply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_state\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribution_strategy_context\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/keras/optimizers/legacy/optimizer_v2.py:806\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m distribution\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mcolocate_vars_with(var):\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m name_scope_only_in_function_or_graph(\n\u001b[1;32m    802\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m eagerly_outside_functions\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m var\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    805\u001b[0m     ):\n\u001b[0;32m--> 806\u001b[0m         update_op \u001b[38;5;241m=\u001b[39m \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m            \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39min_cross_replica_context():\n\u001b[1;32m    813\u001b[0m             \u001b[38;5;66;03m# In cross-replica context, extended.update returns\u001b[39;00m\n\u001b[1;32m    814\u001b[0m             \u001b[38;5;66;03m# a list of update ops from all replicas\u001b[39;00m\n\u001b[1;32m    815\u001b[0m             \u001b[38;5;66;03m# (group=False).\u001b[39;00m\n\u001b[1;32m    816\u001b[0m             update_ops\u001b[38;5;241m.\u001b[39mextend(update_op)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2639\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2639\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_replica_ctx_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2640\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2518\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_fn\u001b[39m(_, \u001b[38;5;241m*\u001b[39mmerged_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerged_kwargs):\n\u001b[1;32m   2516\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(var, fn, merged_args, merged_kwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n\u001b[0;32m-> 2518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreplica_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3110\u001b[0m, in \u001b[0;36mReplicaContextBase.merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3106\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3108\u001b[0m merge_fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3109\u001b[0m     merge_fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 3110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3117\u001b[0m, in \u001b[0;36mReplicaContextBase._merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3114\u001b[0m _push_per_thread_mode(  \u001b[38;5;66;03m# thread-local, so not needed with multiple threads\u001b[39;00m\n\u001b[1;32m   3115\u001b[0m     distribution_strategy_context\u001b[38;5;241m.\u001b[39m_CrossReplicaThreadMode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3117\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3118\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3119\u001b[0m   _pop_per_thread_mode()\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2516\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update.<locals>.merge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_fn\u001b[39m(_, \u001b[38;5;241m*\u001b[39mmerged_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerged_kwargs):\n\u001b[0;32m-> 2516\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2637\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2634\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   2635\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2636\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2639\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2640\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3710\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   3708\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   3709\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 3710\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3716\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   3713\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   3714\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   3715\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 3716\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   3718\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/keras/optimizers/legacy/optimizer_v2.py:785\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply_state\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_apply_args:\n\u001b[1;32m    784\u001b[0m     apply_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply_state\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m apply_state\n\u001b[0;32m--> 785\u001b[0m update_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_apply_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mapply_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var\u001b[38;5;241m.\u001b[39mconstraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies([update_op]):\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow_addons/optimizers/lookahead.py:141\u001b[0m, in \u001b[0;36mLookahead._resource_apply_dense\u001b[0;34m(self, grad, var)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_resource_apply_dense\u001b[39m(\u001b[38;5;28mself\u001b[39m, grad, var):\n\u001b[0;32m--> 141\u001b[0m     train_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_apply_dense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies([train_op]):\n\u001b[1;32m    145\u001b[0m         look_ahead_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_look_ahead_op(var)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow_addons/optimizers/rectified_adam.py:230\u001b[0m, in \u001b[0;36mRectifiedAdam._resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    227\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_slot(var, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_slot(var, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 230\u001b[0m m_t \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbeta_1_t\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mone_minus_beta_1_t\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_locking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_locking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m m_corr_t \u001b[38;5;241m=\u001b[39m m_t \u001b[38;5;241m*\u001b[39m coef[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecip_one_minus_beta_1_power\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    236\u001b[0m v_t \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39massign(\n\u001b[1;32m    237\u001b[0m     coef[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta_2_t\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m v \u001b[38;5;241m+\u001b[39m coef[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone_minus_beta_2_t\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39msquare(grad),\n\u001b[1;32m    238\u001b[0m     use_locking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_locking,\n\u001b[1;32m    239\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:990\u001b[0m, in \u001b[0;36mBaseResourceVariable.assign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    988\u001b[0m   validate_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_shape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\u001b[38;5;241m.\u001b[39mis_fully_defined()\n\u001b[1;32m    989\u001b[0m   kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m validate_shape\n\u001b[0;32m--> 990\u001b[0m assign_op \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_value:\n\u001b[1;32m    993\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_read(assign_op)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:158\u001b[0m, in \u001b[0;36massign_variable_op\u001b[0;34m(resource, value, validate_shape, name)\u001b[0m\n\u001b[1;32m    156\u001b[0m   validate_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    157\u001b[0m validate_shape \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_bool(validate_shape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 158\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAssignVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _op\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:775\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    770\u001b[0m   _ExtractDefaultTypesAndAllowedTypes(op_def, default_type_attr_map,\n\u001b[1;32m    771\u001b[0m                                       allowed_list_attr_map)\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# Requires that op_def has passed validation (using the C++\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# ValidateOpDef() from ../framework/op_def_util.h).\u001b[39;00m\n\u001b[0;32m--> 775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mas_default(), ops\u001b[38;5;241m.\u001b[39mname_scope(name) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[1;32m    776\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fallback:\n\u001b[1;32m    777\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[1;32m    778\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[1;32m    779\u001b[0m                            input_types)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:6872\u001b[0m, in \u001b[0;36minternal_name_scope_v1.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6870\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6871\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_scope \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n\u001b[0;32m-> 6872\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name_scope\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6873\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   6874\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_g_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:4544\u001b[0m, in \u001b[0;36mGraph.name_scope\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4542\u001b[0m   returned_scope \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m   4543\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4544\u001b[0m   new_stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4545\u001b[0m   returned_scope \u001b[38;5;241m=\u001b[39m new_stack \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_stack \u001b[38;5;241m=\u001b[39m new_stack\n",
      "File \u001b[0;32m~/miniconda3/envs/base_3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:4587\u001b[0m, in \u001b[0;36mGraph.unique_name\u001b[0;34m(self, name, mark_as_used)\u001b[0m\n\u001b[1;32m   4584\u001b[0m \u001b[38;5;66;03m# For the sake of checking for names in use, we treat names as case\u001b[39;00m\n\u001b[1;32m   4585\u001b[0m \u001b[38;5;66;03m# insensitive (e.g. foo = Foo).\u001b[39;00m\n\u001b[1;32m   4586\u001b[0m name_key \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m-> 4587\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_names_in_use\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4588\u001b[0m \u001b[38;5;66;03m# Increment the number for \"name_key\".\u001b[39;00m\n\u001b[1;32m   4589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mark_as_used:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CFG.output_dir = ''\n",
    "\n",
    "# train_folds(CFG, [0])\n",
    "#train_folds(CFG, [1])\n",
    "train_folds(CFG, [2])\n",
    "train_folds(CFG, [3])\n",
    "train_folds(CFG, [4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold1 => 150/150 - 77s - loss: 2.0847 - categorical_accuracy: 0.6793 - val_loss: 2.0803 - val_categorical_accuracy: 0.6991 - 77s/epoch - 512ms/step\n",
    "# fold0 => 136/136 - 76s - loss: 2.1338 - categorical_accuracy: 0.6692 - val_loss: 1.6775 - val_categorical_accuracy: 0.7987\n",
    "# fold4 => 145/145 - 71s - loss: 2.1799 - categorical_accuracy: 0.6559 - val_loss: 1.7580 - val_categorical_accuracy: 0.7841 - 71s/epoch - 492ms/step\n",
    "# fold2 => 292/292 - 75s - loss: 1.8099 - categorical_accuracy: 0.8042 - val_loss: 1.8336 - val_categorical_accuracy: 0.7546 -\n",
    "# fold3 => 302/302 - 75s - loss: 1.8459 - categorical_accuracy: 0.7937 - val_loss: 1.8191 - val_categorical_accuracy: 0.7494 - 75s/epoch - 248ms/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WTJ8eruttPxJ",
    "outputId": "d5bdfb3b-a64d-4434-b176-f1d58c2adaa3"
   },
   "outputs": [],
   "source": [
    "# CFG.seed = 42\n",
    "# CFG.comment = f'islr-fp16-192-8-seed{CFG.seed}'\n",
    "# train_folds(CFG, ['all'], summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFG.seed = 43\n",
    "# CFG.comment = f'islr-fp16-192-8-seed{CFG.seed}'\n",
    "# train_folds(CFG, ['all'], summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHLmUWM4tP9S"
   },
   "outputs": [],
   "source": [
    "# CFG.seed = 44\n",
    "# CFG.comment = f'islr-fp16-192-8-seed{CFG.seed}'\n",
    "# train_folds(CFG, ['all'], summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFG.seed = 45\n",
    "# CFG.comment = f'islr-fp16-192-8-seed{CFG.seed}'\n",
    "# train_folds(CFG, ['all'], summary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at4Io1dNtSLh"
   },
   "source": [
    "### Operations applied after metric reached its peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T14:14:58.333097Z",
     "iopub.status.busy": "2023-05-30T14:14:58.332624Z"
    },
    "id": "pRnjnF6Cj9nY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(256, 384, 708), dtype=tf.float32, name=None), TensorSpec(shape=(256, 250), dtype=tf.float32, name=None))> <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 384, 708), dtype=tf.float32, name=None), TensorSpec(shape=(None, 250), dtype=tf.float32, name=None))>\n",
      "\n",
      "\n",
      "---------fold4---------\n",
      "train:74240 valid:18944\n",
      "\n",
      "resume from epoch1\n",
      "Epoch 1/349\n",
      "290/290 - 390s - loss: 3.2344 - categorical_accuracy: 0.4509 - val_loss: 2.1118 - val_categorical_accuracy: 0.6713 - 390s/epoch - 1s/step\n",
      "Epoch 2/349\n",
      "290/290 - 83s - loss: 2.6525 - categorical_accuracy: 0.5744 - val_loss: 2.0035 - val_categorical_accuracy: 0.7180 - 83s/epoch - 287ms/step\n",
      "Epoch 3/349\n",
      "290/290 - 80s - loss: 2.4600 - categorical_accuracy: 0.6271 - val_loss: 1.9653 - val_categorical_accuracy: 0.7333 - 80s/epoch - 275ms/step\n",
      "Epoch 4/349\n",
      "290/290 - 82s - loss: 2.3530 - categorical_accuracy: 0.6540 - val_loss: 1.9389 - val_categorical_accuracy: 0.7418 - 82s/epoch - 283ms/step\n",
      "Epoch 5/349\n",
      "290/290 - 80s - loss: 2.2958 - categorical_accuracy: 0.6701 - val_loss: 1.9233 - val_categorical_accuracy: 0.7479 - 80s/epoch - 277ms/step\n",
      "Epoch 6/349\n",
      "290/290 - 73s - loss: 2.2427 - categorical_accuracy: 0.6828 - val_loss: 1.9070 - val_categorical_accuracy: 0.7515 - 73s/epoch - 253ms/step\n",
      "Epoch 7/349\n",
      "290/290 - 69s - loss: 2.2062 - categorical_accuracy: 0.6941 - val_loss: 1.8988 - val_categorical_accuracy: 0.7555 - 69s/epoch - 236ms/step\n",
      "Epoch 8/349\n",
      "290/290 - 72s - loss: 2.1921 - categorical_accuracy: 0.6995 - val_loss: 1.8898 - val_categorical_accuracy: 0.7580 - 72s/epoch - 247ms/step\n",
      "Epoch 9/349\n",
      "290/290 - 74s - loss: 2.1564 - categorical_accuracy: 0.7102 - val_loss: 1.8839 - val_categorical_accuracy: 0.7598 - 74s/epoch - 256ms/step\n",
      "Epoch 10/349\n",
      "290/290 - 74s - loss: 2.1372 - categorical_accuracy: 0.7137 - val_loss: 1.8736 - val_categorical_accuracy: 0.7605 - 74s/epoch - 254ms/step\n",
      "Epoch 11/349\n",
      "290/290 - 71s - loss: 2.1220 - categorical_accuracy: 0.7175 - val_loss: 1.8718 - val_categorical_accuracy: 0.7610 - 71s/epoch - 245ms/step\n",
      "Epoch 12/349\n",
      "290/290 - 69s - loss: 2.1078 - categorical_accuracy: 0.7223 - val_loss: 1.8692 - val_categorical_accuracy: 0.7624 - 69s/epoch - 237ms/step\n",
      "Epoch 13/349\n",
      "290/290 - 72s - loss: 2.0900 - categorical_accuracy: 0.7272 - val_loss: 1.8680 - val_categorical_accuracy: 0.7613 - 72s/epoch - 248ms/step\n",
      "Epoch 14/349\n",
      "290/290 - 75s - loss: 2.0825 - categorical_accuracy: 0.7316 - val_loss: 1.8621 - val_categorical_accuracy: 0.7645 - 75s/epoch - 258ms/step\n",
      "Epoch 15/349\n",
      "290/290 - 74s - loss: 2.0744 - categorical_accuracy: 0.7318 - val_loss: 1.8593 - val_categorical_accuracy: 0.7647 - 74s/epoch - 255ms/step\n",
      "Epoch 16/349\n",
      "290/290 - 71s - loss: 2.4835 - categorical_accuracy: 0.5716 - val_loss: 1.8496 - val_categorical_accuracy: 0.7620 - 71s/epoch - 244ms/step\n",
      "Epoch 17/349\n",
      "290/290 - 70s - loss: 2.4734 - categorical_accuracy: 0.5680 - val_loss: 1.8480 - val_categorical_accuracy: 0.7633 - 70s/epoch - 241ms/step\n",
      "Epoch 18/349\n",
      "290/290 - 72s - loss: 2.4582 - categorical_accuracy: 0.5707 - val_loss: 1.8507 - val_categorical_accuracy: 0.7616 - 72s/epoch - 248ms/step\n",
      "Epoch 19/349\n",
      "290/290 - 75s - loss: 2.4614 - categorical_accuracy: 0.5717 - val_loss: 1.8511 - val_categorical_accuracy: 0.7624 - 75s/epoch - 258ms/step\n",
      "Epoch 20/349\n",
      "290/290 - 74s - loss: 2.4587 - categorical_accuracy: 0.5706 - val_loss: 1.8385 - val_categorical_accuracy: 0.7648 - 74s/epoch - 255ms/step\n",
      "Epoch 21/349\n",
      "290/290 - 70s - loss: 2.4353 - categorical_accuracy: 0.5752 - val_loss: 1.8389 - val_categorical_accuracy: 0.7650 - 70s/epoch - 242ms/step\n",
      "Epoch 22/349\n",
      "290/290 - 69s - loss: 2.4422 - categorical_accuracy: 0.5746 - val_loss: 1.8389 - val_categorical_accuracy: 0.7650 - 69s/epoch - 238ms/step\n",
      "Epoch 23/349\n",
      "290/290 - 73s - loss: 2.4313 - categorical_accuracy: 0.5752 - val_loss: 1.8397 - val_categorical_accuracy: 0.7633 - 73s/epoch - 251ms/step\n",
      "Epoch 24/349\n",
      "290/290 - 75s - loss: 2.4178 - categorical_accuracy: 0.5806 - val_loss: 1.8368 - val_categorical_accuracy: 0.7663 - 75s/epoch - 259ms/step\n",
      "Epoch 25/349\n",
      "290/290 - 74s - loss: 2.4240 - categorical_accuracy: 0.5782 - val_loss: 1.8337 - val_categorical_accuracy: 0.7638 - 74s/epoch - 255ms/step\n",
      "Epoch 26/349\n",
      "290/290 - 71s - loss: 2.4160 - categorical_accuracy: 0.5812 - val_loss: 1.8279 - val_categorical_accuracy: 0.7665 - 71s/epoch - 245ms/step\n",
      "Epoch 27/349\n",
      "290/290 - 70s - loss: 2.4190 - categorical_accuracy: 0.5807 - val_loss: 1.8254 - val_categorical_accuracy: 0.7651 - 70s/epoch - 240ms/step\n",
      "Epoch 28/349\n",
      "290/290 - 72s - loss: 2.4144 - categorical_accuracy: 0.5784 - val_loss: 1.8344 - val_categorical_accuracy: 0.7647 - 72s/epoch - 247ms/step\n",
      "Epoch 29/349\n",
      "290/290 - 75s - loss: 2.3984 - categorical_accuracy: 0.5856 - val_loss: 1.8317 - val_categorical_accuracy: 0.7646 - 75s/epoch - 258ms/step\n",
      "Epoch 30/349\n",
      "290/290 - 73s - loss: 2.4032 - categorical_accuracy: 0.5820 - val_loss: 1.8291 - val_categorical_accuracy: 0.7664 - 73s/epoch - 253ms/step\n",
      "Epoch 31/349\n",
      "290/290 - 71s - loss: 2.4053 - categorical_accuracy: 0.5851 - val_loss: 1.8278 - val_categorical_accuracy: 0.7659 - 71s/epoch - 244ms/step\n",
      "Epoch 32/349\n",
      "290/290 - 69s - loss: 2.3927 - categorical_accuracy: 0.5865 - val_loss: 1.8304 - val_categorical_accuracy: 0.7655 - 69s/epoch - 237ms/step\n",
      "Epoch 33/349\n",
      "290/290 - 73s - loss: 2.4015 - categorical_accuracy: 0.5853 - val_loss: 1.8294 - val_categorical_accuracy: 0.7651 - 73s/epoch - 252ms/step\n",
      "Epoch 34/349\n",
      "290/290 - 75s - loss: 2.3870 - categorical_accuracy: 0.5853 - val_loss: 1.8254 - val_categorical_accuracy: 0.7668 - 75s/epoch - 258ms/step\n",
      "Epoch 35/349\n",
      "290/290 - 73s - loss: 2.3911 - categorical_accuracy: 0.5861 - val_loss: 1.8277 - val_categorical_accuracy: 0.7657 - 73s/epoch - 252ms/step\n",
      "Epoch 36/349\n",
      "290/290 - 71s - loss: 2.3775 - categorical_accuracy: 0.5891 - val_loss: 1.8267 - val_categorical_accuracy: 0.7658 - 71s/epoch - 244ms/step\n",
      "Epoch 37/349\n",
      "290/290 - 69s - loss: 2.3764 - categorical_accuracy: 0.5913 - val_loss: 1.8252 - val_categorical_accuracy: 0.7671 - 69s/epoch - 240ms/step\n",
      "Epoch 38/349\n",
      "290/290 - 73s - loss: 2.3744 - categorical_accuracy: 0.5895 - val_loss: 1.8218 - val_categorical_accuracy: 0.7666 - 73s/epoch - 251ms/step\n",
      "Epoch 39/349\n",
      "290/290 - 75s - loss: 2.3822 - categorical_accuracy: 0.5899 - val_loss: 1.8241 - val_categorical_accuracy: 0.7674 - 75s/epoch - 260ms/step\n",
      "Epoch 40/349\n",
      "290/290 - 74s - loss: 2.3663 - categorical_accuracy: 0.5934 - val_loss: 1.8215 - val_categorical_accuracy: 0.7663 - 74s/epoch - 254ms/step\n",
      "Epoch 41/349\n",
      "290/290 - 70s - loss: 2.3684 - categorical_accuracy: 0.5921 - val_loss: 1.8240 - val_categorical_accuracy: 0.7688 - 70s/epoch - 241ms/step\n",
      "Epoch 42/349\n",
      "290/290 - 70s - loss: 2.3728 - categorical_accuracy: 0.5928 - val_loss: 1.8193 - val_categorical_accuracy: 0.7686 - 70s/epoch - 240ms/step\n",
      "Epoch 43/349\n",
      "290/290 - 72s - loss: 2.3605 - categorical_accuracy: 0.5954 - val_loss: 1.8199 - val_categorical_accuracy: 0.7670 - 72s/epoch - 249ms/step\n",
      "Epoch 44/349\n",
      "290/290 - 75s - loss: 2.3660 - categorical_accuracy: 0.5937 - val_loss: 1.8259 - val_categorical_accuracy: 0.7668 - 75s/epoch - 260ms/step\n",
      "Epoch 45/349\n",
      "290/290 - 74s - loss: 2.3651 - categorical_accuracy: 0.5945 - val_loss: 1.8231 - val_categorical_accuracy: 0.7674 - 74s/epoch - 254ms/step\n",
      "Epoch 46/349\n",
      "290/290 - 70s - loss: 2.3651 - categorical_accuracy: 0.5953 - val_loss: 1.8203 - val_categorical_accuracy: 0.7669 - 70s/epoch - 243ms/step\n",
      "Epoch 47/349\n",
      "290/290 - 69s - loss: 2.3599 - categorical_accuracy: 0.5947 - val_loss: 1.8187 - val_categorical_accuracy: 0.7692 - 69s/epoch - 237ms/step\n",
      "Epoch 48/349\n",
      "290/290 - 73s - loss: 2.3636 - categorical_accuracy: 0.5930 - val_loss: 1.8221 - val_categorical_accuracy: 0.7687 - 73s/epoch - 252ms/step\n",
      "Epoch 49/349\n",
      "290/290 - 75s - loss: 2.3528 - categorical_accuracy: 0.5970 - val_loss: 1.8249 - val_categorical_accuracy: 0.7659 - 75s/epoch - 259ms/step\n",
      "Epoch 50/349\n",
      "290/290 - 73s - loss: 2.3468 - categorical_accuracy: 0.5990 - val_loss: 1.8219 - val_categorical_accuracy: 0.7673 - 73s/epoch - 252ms/step\n",
      "Epoch 51/349\n",
      "290/290 - 71s - loss: 2.3621 - categorical_accuracy: 0.5986 - val_loss: 1.8203 - val_categorical_accuracy: 0.7671 - 71s/epoch - 243ms/step\n",
      "Epoch 52/349\n",
      "290/290 - 75s - loss: 2.3495 - categorical_accuracy: 0.5966 - val_loss: 1.8193 - val_categorical_accuracy: 0.7684 - 75s/epoch - 258ms/step\n",
      "Epoch 53/349\n",
      "290/290 - 76s - loss: 2.3497 - categorical_accuracy: 0.5985 - val_loss: 1.8199 - val_categorical_accuracy: 0.7671 - 76s/epoch - 262ms/step\n",
      "Epoch 54/349\n",
      "290/290 - 74s - loss: 2.3520 - categorical_accuracy: 0.5977 - val_loss: 1.8255 - val_categorical_accuracy: 0.7664 - 74s/epoch - 256ms/step\n",
      "Epoch 55/349\n",
      "290/290 - 71s - loss: 2.3439 - categorical_accuracy: 0.5995 - val_loss: 1.8215 - val_categorical_accuracy: 0.7675 - 71s/epoch - 246ms/step\n",
      "Epoch 56/349\n",
      "290/290 - 69s - loss: 2.3547 - categorical_accuracy: 0.5994 - val_loss: 1.8218 - val_categorical_accuracy: 0.7673 - 69s/epoch - 239ms/step\n",
      "Epoch 57/349\n",
      "290/290 - 73s - loss: 2.3540 - categorical_accuracy: 0.5982 - val_loss: 1.8196 - val_categorical_accuracy: 0.7688 - 73s/epoch - 253ms/step\n",
      "Epoch 58/349\n",
      "290/290 - 75s - loss: 2.3405 - categorical_accuracy: 0.6002 - val_loss: 1.8200 - val_categorical_accuracy: 0.7673 - 75s/epoch - 259ms/step\n",
      "Epoch 59/349\n",
      "290/290 - 75s - loss: 2.3500 - categorical_accuracy: 0.5981 - val_loss: 1.8157 - val_categorical_accuracy: 0.7694 - 75s/epoch - 257ms/step\n",
      "Epoch 60/349\n",
      "290/290 - 70s - loss: 2.3479 - categorical_accuracy: 0.5991 - val_loss: 1.8201 - val_categorical_accuracy: 0.7680 - 70s/epoch - 243ms/step\n",
      "Epoch 61/349\n",
      "290/290 - 69s - loss: 2.3352 - categorical_accuracy: 0.6020 - val_loss: 1.8170 - val_categorical_accuracy: 0.7672 - 69s/epoch - 239ms/step\n",
      "Epoch 62/349\n",
      "290/290 - 74s - loss: 2.3390 - categorical_accuracy: 0.6011 - val_loss: 1.8225 - val_categorical_accuracy: 0.7657 - 74s/epoch - 254ms/step\n",
      "Epoch 63/349\n",
      "290/290 - 75s - loss: 2.3364 - categorical_accuracy: 0.6024 - val_loss: 1.8189 - val_categorical_accuracy: 0.7672 - 75s/epoch - 260ms/step\n",
      "Epoch 64/349\n",
      "290/290 - 73s - loss: 2.3361 - categorical_accuracy: 0.6013 - val_loss: 1.8200 - val_categorical_accuracy: 0.7674 - 73s/epoch - 250ms/step\n",
      "Epoch 65/349\n",
      "290/290 - 71s - loss: 2.3337 - categorical_accuracy: 0.6020 - val_loss: 1.8229 - val_categorical_accuracy: 0.7667 - 71s/epoch - 245ms/step\n",
      "Epoch 66/349\n",
      "290/290 - 73s - loss: 2.3411 - categorical_accuracy: 0.5991 - val_loss: 1.8201 - val_categorical_accuracy: 0.7679 - 73s/epoch - 253ms/step\n",
      "Epoch 67/349\n",
      "290/290 - 76s - loss: 2.3366 - categorical_accuracy: 0.6033 - val_loss: 1.8206 - val_categorical_accuracy: 0.7674 - 76s/epoch - 263ms/step\n",
      "Epoch 68/349\n"
     ]
    }
   ],
   "source": [
    "CFG.awp = False\n",
    "awp_start_epoch = 1000\n",
    "dropout_start_epoch = 1000\n",
    "CFG.weight_decay = 0.0\n",
    "CFG.lr = 1725e-7#1725e-6\n",
    "CFG.lr_min = 1725e-8\n",
    "CFG.resume = 1\n",
    "CFG.loc = '/kaggle/input/islr-weights/weights'\n",
    "CFG.batch_size = 256\n",
    "\n",
    "train_folds(CFG, [4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
